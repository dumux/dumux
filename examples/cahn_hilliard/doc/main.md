<!-- Important: This file has been automatically generated by generate_example_docs.py. Do not edit this file directly! -->


| [:arrow_left: Back to the main documentation](../README.md) | [:arrow_left: Go back to part 1](model.md) |
|---|---:|



# Cahn-Hilliard equation main program

The file [`main.cc`](main.cc) contains the problem class `CahnHilliardTestProblem`,
properties and traits specific to the test case as well as the `main` function.
The setup consists of four steps:
1. Define the problem setting boundary conditions and the diffusion coefficient
2. Configure the property system reusing the model defined in Part 1
3. Define a function for setting the random initial condition
4. The main program defining all steps of the program

__Table of contents__

[TOC]

We start in `main.cc` with the necessary header includes:
<details><summary> Click to show includes</summary>

```cpp

#include <config.h>
#include <type_traits>
#include <random>

#include <dumux/common/initialize.hh>
#include <dumux/common/properties.hh>
#include <dumux/common/parameters.hh>
#include <dumux/common/numeqvector.hh>
#include <dumux/common/boundarytypes.hh>
#include <dumux/common/fvproblem.hh>

#include <dumux/discretization/box.hh>
#include <dumux/linear/linearsolvertraits.hh>
#include <dumux/linear/linearalgebratraits.hh>
#include <dumux/linear/istlsolvers.hh>
#include <dumux/nonlinear/newtonsolver.hh>
#include <dumux/assembly/fvassembler.hh>

#include <dune/grid/yaspgrid.hh>
#include <dumux/io/vtkoutputmodule.hh>
#include <dumux/io/grid/gridmanager_yasp.hh>

#include "model.hh"
```

</details>

## 1. The problem class

The problem class implements boundary conditions and the source term.
It also provides an interface that is used by the local residual (see Part 1) to obtain
the mobility and surface tension. The values are read from the parameter configuration tree.

<details open>
<summary><b>Click to hide/show the file documentation</b> (or inspect the [source code](../main.cc))</summary>


```cpp
namespace Dumux {
template<class TypeTag>
class CahnHilliardTestProblem : public FVProblem<TypeTag>
{
```

<details><summary> Click to show boilerplate code</summary>

```cpp

    using ParentType = FVProblem<TypeTag>;
    using GridGeometry = GetPropType<TypeTag, Properties::GridGeometry>;
    using FVElementGeometry = typename GridGeometry::LocalView;
    using SubControlVolume = typename GridGeometry::SubControlVolume;
    using GridView = typename GetPropType<TypeTag, Properties::GridGeometry>::GridView;
    using Element = typename GridView::template Codim<0>::Entity;
    using GlobalPosition = typename Element::Geometry::GlobalCoordinate;

    using Scalar = GetPropType<TypeTag, Properties::Scalar>;
    using PrimaryVariables = GetPropType<TypeTag, Properties::PrimaryVariables>;
    using NumEqVector = Dumux::NumEqVector<PrimaryVariables>;
    using BoundaryTypes = Dumux::BoundaryTypes<GetPropType<TypeTag, Properties::ModelTraits>::numEq()>;
    using Indices = typename GetPropType<TypeTag, Properties::ModelTraits>::Indices;
```

</details>
In the constructor, we read the parameter constants from the
parameter tree (which is initialized with the content of `params.input`).

```cpp
public:
    CahnHilliardTestProblem(std::shared_ptr<const GridGeometry> gridGeometry)
    : ParentType(gridGeometry)
    {
        mobility_ = getParam<Scalar>("Problem.Mobility");
        surfaceTension_ = getParam<Scalar>("Problem.SurfaceTension");
        energyScale_ = getParam<Scalar>("Problem.EnergyScale");
    }
```

In the `source` function, we implement the derivative of the free energy.
This demonstrates how parts of the local residual can be split into model specific
parts and parts that might change from scenario to scenario.

```cpp
    template<class ElementVolumeVariables>
    NumEqVector source(const Element &element,
                       const FVElementGeometry& fvGeometry,
                       const ElementVolumeVariables& elemVolVars,
                       const SubControlVolume &scv) const
    {
        NumEqVector values(0.0);
        const auto& c = elemVolVars[scv].concentration();
        values[Indices::chemicalPotentialEqIdx] = -energyScale_*2.0*c*(2.0*c*c - 3*c + 1);
        return values;
    }
```

For the boundary we choose boundary flux (or Neumann) conditions for all equations and on
every part of the boundary, specifying zero flux everywhere for both equations.

```cpp
    BoundaryTypes boundaryTypesAtPos(const GlobalPosition& globalPos) const
    {
        BoundaryTypes values;
        values.setAllNeumann();
        return values;
    }

    NumEqVector neumannAtPos(const GlobalPosition& globalPos) const
    { return { 0.0, 0.0 }; }
```

The parameters interfaces are used in the local residual (see Part 1).
We can name this interface however we want as long as we adapt the calling site
in the `LocalResidual` class in `model.hh`.

```cpp
    Scalar mobility() const
    { return mobility_; }

    Scalar surfaceTension() const
    { return surfaceTension_; }

private:
    Scalar mobility_;
    Scalar surfaceTension_;
    Scalar energyScale_;
};
} // end namespace Dumux
```


</details>

## 2. Property tag and specializations

We create a new tag `DiffusionTest` that inherits all properties
specialized for the tag `DiffusionModel` (we created this in Part 1)
and the tag `BoxModel` which provides types relevant for the spatial
discretization scheme (see [dumux/discretization/box.hh](https://git.iws.uni-stuttgart.de/dumux-repositories/dumux/-/blob/master/dumux/discretization/box.hh)).


<details open>
<summary><b>Click to hide/show the file documentation</b> (or inspect the [source code](../main.cc))</summary>


```cpp
namespace Dumux::Properties::TTag {
struct CahnHilliardTest
{
    using InheritsFrom = std::tuple<CahnHilliardModel, BoxModel>;

    using Grid = Dune::YaspGrid<2>;

    template<class TypeTag>
    using Problem = CahnHilliardTestProblem<TypeTag>;

    using EnableGridGeometryCache = std::true_type;
    using EnableGridVolumeVariablesCache = std::true_type;
    using EnableGridFluxVariablesCache = std::true_type;
};
} // end namespace Dumux::Properties
```


</details>

## 3. Creating the initial solution

To initialize with a random field in parallel, where each processor
creates its own random number sequence, we need to communicate the
resulting values on the processor border and overlap.
See [Diffusion equation example](https://git.iws.uni-stuttgart.de/dumux-repositories/dumux/-/blob/master/examples/diffusion/docs/main.md).
for details. Here in addition, we need to provide a custom scatter operation
that handles vector types. We only need to communicate the first entry (concentration).


<details open>
<summary><b>Click to hide/show the file documentation</b> (or inspect the [source code](../main.cc))</summary>


```cpp
// functor for data communication with MPI
struct MinScatter
{
    template<class A, class B>
    static void apply(A& a, const B& b)
    { a[0] = std::min(a[0], b[0]); }
};

// create the random initial solution
template<class SolutionVector, class GridGeometry>
SolutionVector createInitialSolution(const GridGeometry& gg)
{
    SolutionVector sol(gg.numDofs());

    // Generate random number and add processor offset
    // For sequential runs `rank` always returns `0`.
    std::mt19937 gen(0); // seed is 0 for deterministic results
    std::uniform_real_distribution<> dis(0.0, 1.0);
    for (int n = 0; n < sol.size(); ++n)
    {
        sol[n][0] = 0.42 + 0.02*(0.5-dis(gen)) + gg.gridView().comm().rank();
        sol[n][1] = 0.0;
    }

    // We take the value of the processor with the minimum rank
    // and subtract the rank offset
    if (gg.gridView().comm().size() > 1)
    {
        Dumux::VectorCommDataHandle<
            typename GridGeometry::VertexMapper,
            SolutionVector,
            GridGeometry::GridView::dimension,
            MinScatter
        > minHandle(gg.vertexMapper(), sol);
        gg.gridView().communicate(minHandle, Dune::All_All_Interface, Dune::ForwardCommunication);

        // Remove processor offset
        for (int n = 0; n < sol.size(); ++n)
            sol[n][0] -= std::floor(sol[n][0]);
    }
    return sol;
}
```


</details>

## 4. The main program

The `main` function sets up the simulation framework, initializes runtime parameters,
creates the grid and storage vectors
for the variables, primary and secondary. It specifies and constructs and assembler, which
assembles the discretized residual and system matrix (Jacobian of the model residual), as well as
a linear solver. A Newton method is used to solve the nonlinear equations where in each Newton iteration
the Jacobian and the residual needs to be reassembled and the resulting linear system is solved.
The time loop controls the time stepping. Here, we let the Newton solver suggest an adaption of
the time step size based on the convergence history of the nonlinear solver.


<details open>
<summary><b>Click to hide/show the file documentation</b> (or inspect the [source code](../main.cc))</summary>


```cpp
int main(int argc, char** argv)
{
    using namespace Dumux;
```

We initialize MPI and/or multithreading backend. When not running
in parallel the MPI setup is skipped.

```cpp
    Dumux::initialize(argc, argv);
```

Then we initialize parameter tree.

```cpp
    Parameters::init(argc, argv);
```

We create an alias for the type tag for this problem
and extract type information through properties.

```cpp
    using TypeTag = Properties::TTag::CahnHilliardTest;

    using Scalar = GetPropType<TypeTag, Properties::Scalar>;
    using Grid = GetPropType<TypeTag, Properties::Grid>;
    using GridGeometry = GetPropType<TypeTag, Properties::GridGeometry>;
    using Problem = GetPropType<TypeTag, Properties::Problem>;
    using SolutionVector = GetPropType<TypeTag, Properties::SolutionVector>;
    using GridVariables = GetPropType<TypeTag, Properties::GridVariables>;
```

We initialize the grid, grid geometry, problem, solution vector, and grid variables.

```cpp
    GridManager<Grid> gridManager;
    gridManager.init();

    auto gridGeometry = std::make_shared<GridGeometry>(gridManager.grid().leafGridView());
    auto problem = std::make_shared<Problem>(gridGeometry);
    auto sol = createInitialSolution<SolutionVector>(*gridGeometry);
    auto gridVariables = std::make_shared<GridVariables>(problem, gridGeometry);
    gridVariables->init(sol);
```

We initialize the VTK output module and write out the initial concentration and chemical potential

```cpp
    VtkOutputModule<GridVariables, SolutionVector> vtkWriter(*gridVariables, sol, problem->name());
    vtkWriter.addVolumeVariable([](const auto& vv){ return vv.concentration(); }, "c");
    vtkWriter.addVolumeVariable([](const auto& vv){ return vv.chemicalPotential(); }, "mu");
    vtkWriter.write(0.0);
```

We instantiate time loop using start and end time as well as
the time step size from the parameter tree (`params.input`)

```cpp
    auto timeLoop = std::make_shared<CheckPointTimeLoop<Scalar>>(
        getParam<Scalar>("TimeLoop.TStart", 0.0),
        getParam<Scalar>("TimeLoop.InitialTimeStepSize"),
        getParam<Scalar>("TimeLoop.TEnd")
    );
```

We set the maximum time step size allowed in the adaptive time stepping scheme.

```cpp
    timeLoop->setMaxTimeStepSize(getParam<Scalar>("TimeLoop.MaxTimeStepSize"));
```

Next, we choose the type of assembler, linear solver and PDE solver
and construct instances of these classes.

```cpp
    using Assembler = FVAssembler<TypeTag, DiffMethod::numeric>;
    using LinearSolver = SSORBiCGSTABIstlSolver<LinearSolverTraits<GridGeometry>, LinearAlgebraTraitsFromAssembler<Assembler>>;
    using Solver = Dumux::NewtonSolver<Assembler, LinearSolver>;

    auto oldSol = sol;
    auto assembler = std::make_shared<Assembler>(problem, gridGeometry, gridVariables, timeLoop, oldSol);
    auto linearSolver = std::make_shared<LinearSolver>(gridGeometry->gridView(), gridGeometry->dofMapper());
    Solver solver(assembler, linearSolver);
```

The time loop is where most of the actual computations happen.
We assemble and solve the linear system of equations, update the solution,
write the solution to a VTK file and continue until the we reach the
final simulation time.


```cpp
    timeLoop->start(); do
    {
        // Assemble & solve
        // Passing the time loop enables the solver to repeat the time step
        // with a reduced time step size if the Newton solver does not converge.
        solver.solve(sol, *timeLoop);

        // make the new solution the old solution
        oldSol = sol;
        gridVariables->advanceTimeStep();

        // advance to the time loop to the next step
        timeLoop->advanceTimeStep();

        // write VTK output (concentration field and chemical potential)
        vtkWriter.write(timeLoop->time());

        // report statistics of this time step
        timeLoop->reportTimeStep();

        // set new dt as suggested by the Newton solver
        timeLoop->setTimeStepSize(solver.suggestTimeStepSize(timeLoop->timeStepSize()));

    } while (!timeLoop->finished());

    // print the final report
    timeLoop->finalize(gridGeometry->gridView().comm());
    return 0;
}
```


</details>


| [:arrow_left: Back to the main documentation](../README.md) | [:arrow_left: Go back to part 1](model.md) |
|---|---:|

